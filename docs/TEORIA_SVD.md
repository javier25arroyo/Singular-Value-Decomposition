# üìê Teor√≠a de SVD (Descomposici√≥n en Valores Singulares)

## ¬øQu√© es SVD?

La **Descomposici√≥n en Valores Singulares** (SVD por sus siglas en ingl√©s: Singular Value Decomposition) es una de las factorizaciones de matrices m√°s importantes en √°lgebra lineal.

Para cualquier matriz **A** de dimensiones m√ón, SVD la descompone en tres matrices:

```
A = U √ó Œ£ √ó V^T
```

Donde:
- **U** es una matriz ortogonal m√óm (vectores singulares izquierdos)
- **Œ£** es una matriz diagonal m√ón con valores singulares no negativos
- **V^T** es la transpuesta de una matriz ortogonal n√ón (vectores singulares derechos)

## Propiedades Matem√°ticas

### 1. Valores Singulares
Los valores singulares œÉ‚ÇÅ, œÉ‚ÇÇ, ..., œÉ·µ£ en la diagonal de Œ£ est√°n ordenados:
```
œÉ‚ÇÅ ‚â• œÉ‚ÇÇ ‚â• ... ‚â• œÉ·µ£ ‚â• 0
```

donde r es el rango de la matriz A.

### 2. Matrices Ortogonales
Las matrices U y V son ortogonales, lo que significa:
```
U^T √ó U = I
V^T √ó V = I
```

### 3. Relaci√≥n con Autovalores
Los valores singulares de A son las ra√≠ces cuadradas de los autovalores de A^T√óA (o A√óA^T):
```
œÉ·µ¢ = ‚àöŒª·µ¢
```

## Aplicaci√≥n en Compresi√≥n de Im√°genes

### Paso 1: Representaci√≥n Matricial
Una imagen digital se puede representar como una matriz:
- **Escala de grises**: Matriz m√ón donde cada elemento es la intensidad del p√≠xel
- **Color (RGB)**: Tres matrices m√ón, una por cada canal de color

### Paso 2: Descomposici√≥n
Para cada canal de color:
```
Canal_Rojo = U_R √ó Œ£_R √ó V_R^T
```

### Paso 3: Aproximaci√≥n de Rango Bajo
En lugar de usar todos los valores singulares, usamos solo los k m√°s grandes:

```
A_k = U[:, 1:k] √ó Œ£[1:k, 1:k] √ó V^T[1:k, :]
```

### Paso 4: Reconstrucci√≥n
La imagen comprimida se obtiene recombinando los k componentes principales.

## ¬øPor Qu√© Funciona?

### Teorema de Eckart-Young
SVD proporciona la **mejor aproximaci√≥n** de rango k a una matriz en el sentido de:
- Norma de Frobenius
- Norma espectral

Esto significa que A_k minimiza el error:
```
||A - A_k|| = m√≠nimo
```

### Interpretaci√≥n Geom√©trica
Los valores singulares representan la "importancia" de cada componente:
- **Valores grandes**: Caracter√≠sticas principales de la imagen
- **Valores peque√±os**: Detalles finos y ruido

Al mantener solo los k valores m√°s grandes, preservamos las caracter√≠sticas m√°s importantes.

## An√°lisis de Compresi√≥n

### Tama√±o Original
Para una imagen m√ón con c canales:
```
Tama√±o_original = m √ó n √ó c
```

### Tama√±o Comprimido
Con k valores singulares por canal:
```
Tama√±o_comprimido = k √ó (m + n + 1) √ó c
```

Esto incluye:
- k columnas de U (m elementos cada una)
- k valores singulares
- k filas de V^T (n elementos cada una)

### Ratio de Compresi√≥n
```
Ratio = Tama√±o_original / Tama√±o_comprimido
      = (m √ó n √ó c) / (k √ó (m + n + 1) √ó c)
      = (m √ó n) / (k √ó (m + n + 1))
```

### Energ√≠a Retenida
El porcentaje de informaci√≥n preservada:
```
Energ√≠a = (Œ£·µ¢‚Çå‚ÇÅ·µè œÉ·µ¢¬≤) / (Œ£·µ¢‚Çå‚ÇÅ ≥ œÉ·µ¢¬≤) √ó 100%
```

## Ejemplos Num√©ricos

### Ejemplo 1: Matriz Simple
```python
A = [[3, 1, 1],
     [-1, 3, 1]]

U, Œ£, V^T = SVD(A)

U ‚âà [[-0.71, -0.71],
     [-0.71,  0.71]]

Œ£ ‚âà [3.74, 0]
    [0,    2.83]

V^T ‚âà [[-0.34, -0.91, -0.24],
       [-0.91,  0.26,  0.33]]
```

### Ejemplo 2: Compresi√≥n de Imagen 100√ó100

**Sin compresi√≥n (k=100):**
- Tama√±o: 100 √ó 100 √ó 3 = 30,000 valores
- Energ√≠a: 100%
- Calidad: Perfecta

**Compresi√≥n alta (k=10):**
- Tama√±o: 10 √ó (100 + 100 + 1) √ó 3 = 6,030 valores
- Ratio: 4.98x
- Energ√≠a: ~85%
- Calidad: Buena, detalles borrosos

**Compresi√≥n media (k=50):**
- Tama√±o: 50 √ó (100 + 100 + 1) √ó 3 = 30,150 valores
- Ratio: 0.99x (no hay compresi√≥n efectiva)
- Energ√≠a: ~99%
- Calidad: Excelente

## Ventajas y Desventajas

### ‚úÖ Ventajas
1. **√ìptima**: Mejor aproximaci√≥n posible para un rango dado
2. **Controlable**: Ajuste fino entre compresi√≥n y calidad
3. **Interpretable**: Los componentes tienen significado matem√°tico
4. **Estable**: Num√©ricamente robusta
5. **Vers√°til**: Aplicable a cualquier matriz

### ‚ùå Desventajas
1. **Costo computacional**: O(min(m¬≤n, mn¬≤)) para calcular SVD completo
2. **No espec√≠fica para im√°genes**: M√©todos como JPEG son m√°s eficientes
3. **P√©rdida de informaci√≥n**: Compresi√≥n con p√©rdida
4. **Almacenamiento de U y V**: Requiere guardar matrices adicionales

## Comparaci√≥n con Otros M√©todos

| M√©todo | Ratio t√≠pico | Calidad | Velocidad | Est√°ndar |
|--------|-------------|---------|-----------|----------|
| **SVD** | 2-10x | Buena | Media | No |
| **JPEG** | 10-100x | Variable | R√°pida | S√≠ |
| **PNG** | 2-3x | Perfecta | R√°pida | S√≠ |
| **WebP** | 20-30x | Buena | R√°pida | S√≠ |

## Aplicaciones Adicionales de SVD

Adem√°s de compresi√≥n de im√°genes, SVD se usa en:

1. **Sistemas de recomendaci√≥n**: Netflix, Amazon
2. **Procesamiento de lenguaje natural**: LSA (Latent Semantic Analysis)
3. **Reducci√≥n de dimensionalidad**: PCA est√° relacionado con SVD
4. **Eliminaci√≥n de ruido**: Filtrado de se√±ales
5. **An√°lisis de datos**: Identificaci√≥n de patrones
6. **Visi√≥n por computadora**: Reconocimiento facial
7. **√Ålgebra lineal num√©rica**: Soluci√≥n de sistemas

## Implementaci√≥n Eficiente

### Algoritmos Comunes
1. **SVD completo**: M√©todo de Golub-Kahan
2. **SVD truncado**: Algoritmo de Lanczos
3. **Randomized SVD**: Para matrices grandes

### En Python
```python
import numpy as np

# SVD completo
U, s, VT = np.linalg.svd(A, full_matrices=False)

# SVD truncado (m√°s r√°pido para k peque√±o)
from scipy.sparse.linalg import svds
U, s, VT = svds(A, k=50)
```

## Referencias

1. Golub, G. H., & Van Loan, C. F. (2013). *Matrix Computations*. Johns Hopkins University Press.
2. Trefethen, L. N., & Bau, D. (1997). *Numerical Linear Algebra*. SIAM.
3. Strang, G. (2016). *Introduction to Linear Algebra*. Wellesley-Cambridge Press.
4. Eckart, C., & Young, G. (1936). "The approximation of one matrix by another of lower rank". *Psychometrika*.

## Ejercicios Propuestos

1. **B√°sico**: Calcula manualmente SVD de la matriz [[1, 2], [2, 1]]
2. **Intermedio**: Implementa compresi√≥n SVD sin librer√≠as (solo operaciones b√°sicas)
3. **Avanzado**: Compara SVD con PCA para reducci√≥n de dimensionalidad
4. **Aplicado**: Usa SVD para eliminar ruido de una imagen

---

*Esta documentaci√≥n forma parte del proyecto SVD Image Compression para el curso de √Ålgebra Lineal.*
